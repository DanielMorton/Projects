{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0068a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score\n",
    "from meta_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a16022",
   "metadata": {},
   "source": [
    "## Load Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faad6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./passerine.pickle', 'rb') as f:\n",
    "    passerine = pickle.load(f)\n",
    "    \n",
    "df = pd.DataFrame({\"file\":[f.decode() for f in passerine[\"file\"]],\n",
    "                   \"gt\": passerine[\"gt\"]})\n",
    "for n in passerine:\n",
    "    if type(n) == int:\n",
    "        df[n] = passerine[n][\"predict\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe06494",
   "metadata": {},
   "source": [
    "## Load Bird MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db35fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BIRD_DIR = '/Users/dmorton/Local Documents/Cornell Birds/nabirds/'\n",
    "def read_meta():\n",
    "    hierarcy, parent_map, top_levels, terminal_levels = read_hierarchy(BIRD_DIR)\n",
    "    class_labels = read_class_labels(top_levels, parent_map, BIRD_DIR)\n",
    "    classes, terminal_classes = read_classes(terminal_levels, BIRD_DIR)\n",
    "\n",
    "    meta = class_labels.merge(classes).merge(classes.rename(columns={'label_name': 'class_name',\n",
    "                                                                'id': 'class_id'})\\\n",
    "                           .drop(columns = ['annotation', 'name']))\n",
    "    name_map = {row['name']: idx + 1 for idx, row in meta[['name']].drop_duplicates()\\\n",
    "                                                             .reset_index(drop=True)\\\n",
    "                                                             .iterrows()}\n",
    "    terminal_map = {row['label_name']: idx + 1 for idx, row in terminal_classes.iterrows()}\n",
    "    meta['name_id'] = meta['name'].apply(lambda n: name_map[n])\n",
    "    meta['terminal_id'] = meta['label_name'].apply(lambda n: terminal_map[n])\n",
    "\n",
    "    images = read_images(BIRD_DIR)\n",
    "    boxes = read_boxes(BIRD_DIR)\n",
    "    sizes = read_sizes(BIRD_DIR)\n",
    "    train_test = read_train_test(BIRD_DIR)\n",
    "    train_test_meta = images.merge(meta).merge(boxes).merge(sizes).merge(train_test)\\\n",
    "                          .reset_index(drop=True)\n",
    "    for c, d in zip(train_test_meta.columns, train_test_meta.dtypes):\n",
    "        if d == np.dtype('int64'):\n",
    "            train_test_meta[c] = train_test_meta[c].astype(np.int32)\n",
    "    train_meta = train_test_meta[train_test_meta['is_train'] == 1].drop(columns = 'is_train').reset_index(drop=True)\n",
    "    test_meta = train_test_meta[train_test_meta['is_train'] == 0].drop(columns = 'is_train').reset_index(drop=True)\n",
    "\n",
    "    bad_train_file = '0853/1b7756d652e24d3cab075360168d5960.jpg'\n",
    "    bad_test_file = '0554/f8e98e5ae4b34355ab635b92a74f1779.jpg'\n",
    "    train_meta = correct_record(train_meta, bad_train_file)\n",
    "    test_meta = correct_record(test_meta, bad_test_file)\n",
    "    train_boxes = make_box_df(train_meta, label_col=\"class_id\")\n",
    "    test_boxes = make_box_df(test_meta, label_col=\"class_id\")\n",
    "\n",
    "    return train_meta, test_meta, train_boxes, test_boxes\n",
    "\n",
    "train_meta, test_meta, train_boxes, test_boxes = read_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b9a10",
   "metadata": {},
   "source": [
    "## Add class names to model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6e75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_meta[[\"file\", \"class_name\"]].merge(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413f827",
   "metadata": {},
   "source": [
    "## Class Accuracy - 0% mislabeled training data.\n",
    "\n",
    "Cuckoos, who look plausibly like passerines had the lowest accuracy.\n",
    "\n",
    "Perching Birds (aka passerines) fall in the middle range for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8354808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "Cuckoos                                                    86.7\n",
       "Nightjars                                                  92.3\n",
       "Parrots                                                    96.4\n",
       "Kingfishers and Allies                                     96.7\n",
       "Woodpeckers                                                96.8\n",
       "Hawks, Kites, Eagles, and Allies                           98.2\n",
       "Swifts and Hummingbirds                                    98.2\n",
       "Owls                                                       98.4\n",
       "Grouse, Quail, and Allies                                  98.5\n",
       "Perching Birds                                             98.6\n",
       "Loons                                                      98.7\n",
       "Cranes and Rails                                           99.0\n",
       "Caracaras and Falcons                                      99.1\n",
       "Pigeons and Doves                                          99.2\n",
       "Frigatebirds, Boobies, Cormorants, Darters, and Allies     99.3\n",
       "Grebes                                                     99.5\n",
       "Plovers, Sandpipers, and Allies                            99.7\n",
       "Ducks, Geese, and Swans                                    99.8\n",
       "Pelicans, Herons, Ibises, and Allies                       99.8\n",
       "Gulls, Terns, and Allies                                   99.8\n",
       "Skuas and Alcids                                          100.0\n",
       "Storks                                                    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df.groupby('class_name').apply(lambda row: (row['gt'] == (row[0] > 0.5)).sum()/row.shape[0]).sort_values() * 100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08df3d",
   "metadata": {},
   "source": [
    "## Class Accuracy - 40% mislabeled data\n",
    "\n",
    "Passerines are the most accurate class. The model struggles with non-passerine accuracy, never higher than 60% and around 50% overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2433069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "Cuckoos                                                   23.0\n",
       "Loons                                                     24.8\n",
       "Ducks, Geese, and Swans                                   40.4\n",
       "Nightjars                                                 41.0\n",
       "Parrots                                                   42.9\n",
       "Grebes                                                    44.8\n",
       "Skuas and Alcids                                          45.1\n",
       "Woodpeckers                                               45.4\n",
       "Frigatebirds, Boobies, Cormorants, Darters, and Allies    47.7\n",
       "Pigeons and Doves                                         50.4\n",
       "Gulls, Terns, and Allies                                  51.1\n",
       "Plovers, Sandpipers, and Allies                           51.2\n",
       "Cranes and Rails                                          56.0\n",
       "Grouse, Quail, and Allies                                 56.1\n",
       "Hawks, Kites, Eagles, and Allies                          56.7\n",
       "Kingfishers and Allies                                    56.7\n",
       "Storks                                                    58.9\n",
       "Caracaras and Falcons                                     59.0\n",
       "Owls                                                      59.2\n",
       "Swifts and Hummingbirds                                   59.3\n",
       "Pelicans, Herons, Ibises, and Allies                      60.4\n",
       "Perching Birds                                            85.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df.groupby('class_name').apply(lambda row: (row['gt'] == (row[40] > 0.5)).sum()/row.shape[0]).sort_values() * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24c14b",
   "metadata": {},
   "source": [
    "Passerine vs. non-passerine accuracy for each model. Ground truth is 1 for passerine, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c416668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.9</td>\n",
       "      <td>98.2</td>\n",
       "      <td>96.4</td>\n",
       "      <td>89.9</td>\n",
       "      <td>86.9</td>\n",
       "      <td>50.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.6</td>\n",
       "      <td>98.3</td>\n",
       "      <td>94.4</td>\n",
       "      <td>95.2</td>\n",
       "      <td>88.2</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1    10    20    30    40\n",
       "gt                                    \n",
       "0   98.9  98.2  96.4  89.9  86.9  50.1\n",
       "1   98.6  98.3  94.4  95.2  88.2  85.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_fp = df[['gt']].merge((df[[0, 1, 10, 20, 30, 40]] > 0.5)* 1.0 == df[['gt']].values,\n",
    "                left_index=True, right_index=True)\n",
    "np.round(tp_fp.groupby('gt').sum()/tp_fp.groupby('gt').count() * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfce8e",
   "metadata": {},
   "source": [
    "ROC remains high, over 90% for training data with 30% errors, indicating that the data is still well separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3bacf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40: 77.5\n",
      "30: 94.7\n",
      "20: 98.0\n",
      "10: 99.0\n",
      "1: 99.8\n",
      "0: 99.9\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[3:]:\n",
    "    print(f\"{col}: {np.round(roc_auc_score(df['gt'], df[col]) * 100,1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
