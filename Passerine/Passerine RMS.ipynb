{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Passerine RMS.ipynb","provenance":[{"file_id":"1P9MHyfaIDCh9zHS0wi1uPFgBdsDB9gU5","timestamp":1631668666461},{"file_id":"1PAT4qBC0oNu1CH2GejkWzkGAWIkuNSO_","timestamp":1582411190068},{"file_id":"18TMgF0BBubj1y8eoN5wOac9gg4Vqbhq1","timestamp":1581629016089},{"file_id":"1j32Kjek-U8m1tCMg24_wqkcr5v_5G3au","timestamp":1581528996987},{"file_id":"1J4fOck3Wc2WfrrSTKk87BHCiRLTXuA8n","timestamp":1581521287668},{"file_id":"1UOJ1Z2aocaY8udv0I5tDmldd-8tXO4qF","timestamp":1581451341715}],"collapsed_sections":[],"mount_file_id":"1UO5gspcjBuZ-9Zjd6rMo2MYa0oSRHKiD","authorship_tag":"ABX9TyPKHe4bwHyVlBvu9XRf3dAW"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tYMgiqMuCLJ3"},"source":["## **Trains model to predict whether a bird is a passerine or non-passerine.**\n","\n","Uses EfficientNetB4 and Cornell NABirds data previously converted to TFRecord and stored on Google Cloud.\n","\n","Trains models with a set amount of data mislabeled. Percent of mislabeled data is determined by `CUTOFF` and is split proportionally between the two classes."]},{"cell_type":"code","metadata":{"id":"ebZqJFIi7GWC"},"source":["from google.colab import auth\n","auth.authenticate_user()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUgsbIfKyS7a","executionInfo":{"status":"ok","timestamp":1632334718014,"user_tz":240,"elapsed":233,"user":{"displayName":"Daniel Morton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxdX_X4qG11j5MBUgqAy-1QxhxaucRZ1oLJFwguw=s64","userId":"10030415829092908707"}},"outputId":"9f414806-51d6-4c4b-faf3-c9d2456c92f2"},"source":["import numpy as np\n","import pandas as pd\n","\n","import cv2\n","import json \n","import os\n","import zipfile\n","import matplotlib.pyplot as plt\n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.framework import ops\n","print(tf.__version__)\n","\n","AUTO = tf.data.experimental.AUTOTUNE\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"HTrP3CHcm55S"},"source":["**Load train, validation, and metadata.**\n","\n","`split_lookup` contains the 100-fold split of the training data stratified by passerine/non-passerine bird. The folds are labeld 0-99. During training, all folds below the given `CUTOFF` are mislabeled, while the remaining folds are given the correct label."]},{"cell_type":"code","metadata":{"id":"Em3Lk27cyp4H"},"source":["GCS_PATH=\"gs://dmorton-cornell\"\n","\n","GCS_TRAIN = GCS_PATH + '/tf_train/tfrecord*'\n","train_files = tf.io.gfile.glob(GCS_TRAIN)\n","\n","GCS_VALID = GCS_PATH + '/tf_val/tfrecord*'\n","valid_files = tf.io.gfile.glob(GCS_VALID)\n","\n","train_meta = pd.read_csv(\"drive/MyDrive/Birds/train_meta.csv\", index_col=0)\n","split_lookup = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(train_meta['file'].values,\n","                                                                             train_meta['split'].values),\n","                                         default_value=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zMzbxWWsliv-"},"source":["# **Preprocessing**\n","\n","Decodes TFRecord.\n","\n","Assigns `class_id` 22 (perching birds) to true for training images in the folds above the `CUTOFF`. Otherwise all other classes are assigned true and `class_id` 22 is assigned false.\n","\n","Preprocessing consists of random cropping and resizing for training and cropping to the bounding box, padding, and resizing for validation."]},{"cell_type":"code","metadata":{"id":"aF9XvkZ2y-j3"},"source":["BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n","PATH = '/content/sample_data/'\n","SHUFFLE = 2048\n","CUTOFF = 40\n","\n","def decode_jpeg(example, train=False):\n","  features = {\n","      \"filename\": tf.io.FixedLenFeature([], tf.string),\n","\n","      \"class_id\": tf.io.FixedLenFeature([], tf.int64),\n","      \"class_name\": tf.io.FixedLenFeature([], tf.string),\n","\n","      \"name_id\": tf.io.FixedLenFeature([], tf.int64),\n","      \"name\": tf.io.FixedLenFeature([], tf.string),\n","\n","      \"terminal_id\": tf.io.FixedLenFeature([], tf.int64),\n","      \"label_name\": tf.io.FixedLenFeature([], tf.string),\n","\n","      \"xmin\": tf.io.FixedLenFeature([], tf.float32),\n","      \"ymin\": tf.io.FixedLenFeature([], tf.float32),\n","      \"xmax\": tf.io.FixedLenFeature([], tf.float32),\n","      \"ymax\": tf.io.FixedLenFeature([], tf.float32),\n","      \n","      \"image\": tf.io.FixedLenFeature([], tf.string),\n","      \"height\": tf.io.FixedLenFeature([], tf.int64),\n","      \"width\": tf.io.FixedLenFeature([], tf.int64)  \n","  }\n","  example = tf.io.parse_single_example(example, features)\n","  height, width = tf.cast(example['height'], tf.int32), tf.cast(example['width'], tf.int32)\n","  img_dim = (height, width, 3)\n","\n","  decoded = tf.image.decode_jpeg(example['image'], channels=3)\n","  image = tf.reshape(decoded, img_dim)\n","  if train and split_lookup.lookup(example['filename']) < CUTOFF:\n","    oh = tf.cast(example['class_id'] != 22, tf.int8)\n","  else:\n","    oh = tf.cast(example['class_id'] == 22, tf.int8)\n","\n","  xmin = example['xmin']\n","  ymin = example['ymin']\n","  xmax = example['xmax']\n","  ymax = example['ymax']\n","  if train:\n","    bbox = tf.expand_dims(tf.expand_dims(tf.stack([ymin, xmin, ymax, xmax]), 0), 0)\n","    return image, oh, tf.clip_by_value(bbox, 0.0, 1.0)\n","  else:\n","    bbox = tf.stack([ymin, xmin, ymax, xmax])\n","    bbox = tf.clip_by_value(bbox, 0.0, 1.0)\n","    bbox = bbox * tf.cast(tf.stack([height, width, height, width]), tf.float32)\n","    bbox = tf.cast(bbox, tf.int32)\n","    return image, oh, bbox\n","\n","def distorted_bounding_box_crop(image,\n","                                bbox = tf.constant([0.0, 0.0, 1.0, 1.0],\n","                                                   dtype=tf.float32,\n","                                                   shape=[1, 1, 4]),\n","                                min_object_covered=0.1,\n","                                aspect_ratio_range=(0.75, 1.33),\n","                                area_range=(0.05, 1.0),\n","                                max_attempts=1000):\n","    bbox_begin, bbox_size, distort_bbox = tf.image.sample_distorted_bounding_box(\n","        tf.shape(image),\n","        bounding_boxes=bbox,\n","        min_object_covered=min_object_covered,\n","        aspect_ratio_range=aspect_ratio_range,\n","        area_range=area_range,\n","        max_attempts=max_attempts,\n","        use_image_if_no_bounding_boxes=True)\n","\n","    cropped_image = tf.slice(image, bbox_begin, bbox_size)\n","    return cropped_image\n","\n","def parse_train_tfrecord(example, target_size):\n","\n","  image, oh, bbox = decode_jpeg(example, train=True)\n","  image = distorted_bounding_box_crop(image, bbox)\n","  image.set_shape([None, None, 3])\n","  image = tf.image.resize(image, (target_size, target_size))\n","  image = tf.keras.applications.efficientnet.preprocess_input(image)\n","\n","  return image, oh\n","\n","def parse_val_tfrecord(example, target_size):\n","  image, oh, bbox = decode_jpeg(example)\n","  image = tf.image.crop_to_bounding_box(image, bbox[0], bbox[1],\n","                                               bbox[2]-bbox[0], bbox[3]-bbox[1])\n","  image = tf.keras.applications.efficientnet.preprocess_input(image)\n","  image = tf.image.resize_with_pad(image, target_size, target_size)\n","  return image, oh\n","  \n","\n","def load_dataset(filenames, train=False):\n","  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n","  records = tf.data.TFRecordDataset(filenames,\n","                                   num_parallel_reads=AUTO)\n","  if train:\n","    return records.map(lambda r: parse_train_tfrecord(r, 380),\n","                        num_parallel_calls=AUTO)\n","  else:\n","    return records.map(lambda r: parse_val_tfrecord(r, 380),\n","                        num_parallel_calls=AUTO)\n","\n","def get_datasets():\n","  train = load_dataset(train_files, train=True).repeat()\\\n","                                               .shuffle(SHUFFLE)\\\n","                                               .batch(BATCH_SIZE)\\\n","                                               .prefetch(AUTO) \n","\n","  val = load_dataset(valid_files).batch(BATCH_SIZE).prefetch(AUTO)\n","  return train, val\n","\n","\n","train_ds, val_ds = get_datasets()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WuhM9quT_Sxd"},"source":["**Sets up the learning rate scheduler.**\n","\n","Learning rate decreases after each batch exponentially so that it drops by a factor of 0.94 after every four epochs."]},{"cell_type":"code","metadata":{"id":"r50trpZkxTl_"},"source":["LOG_LR = 3\n","COEFF_LR = 2.56\n","LR = COEFF_LR * 10**(-LOG_LR)\n","TRAIN_SIZE = 23929\n","STEPS_PER_EPOCH = TRAIN_SIZE//BATCH_SIZE\n","\n","\n","class StepLearningRateScheduler(tf.keras.callbacks.Callback):\n","\n","  def __init__(self, decay_rate=0.94,\n","                     decay_epoch=4,\n","                     steps_per_epoch=STEPS_PER_EPOCH,\n","                     verbose=True):\n","    self.decay_rate = decay_rate\n","    self.decay_epoch = decay_epoch\n","    self.steps_per_epoch = steps_per_epoch\n","    self.verbose=verbose\n","\n","  def schedule(self, batch, lr):\n","    return self.decay_rate ** (1/(self.steps_per_epoch * self.decay_epoch)) * lr\n","\n","  def on_batch_begin(self, batch, logs=None):\n","    if not hasattr(self.model.optimizer, 'lr'):\n","      raise ValueError('Optimizer must have a \"lr\" attribute.')\n","    try:  # new API\n","      lr = float(K.get_value(self.model.optimizer.lr))\n","      lr = self.schedule(batch, lr)\n","    except TypeError:  # Support for old API for backward compatibility\n","      lr = self.schedule(batch)\n","    if not isinstance(lr, (ops.Tensor, float, np.float32, np.float64)):\n","      raise ValueError('The output of the \"schedule\" function '\n","                       'should be float.')\n","    if isinstance(lr, ops.Tensor) and not lr.dtype.is_floating:\n","      raise ValueError('The dtype of Tensor should be float')\n","    K.set_value(self.model.optimizer.lr, K.get_value(lr))\n","\n","  def on_epoch_end(self, epoch, logs=None):\n","    logs = logs or {}\n","    logs['lr'] = K.get_value(self.model.optimizer.lr)\n","    if self.verbose:\n","      print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n","            'rate to %s.' % (epoch + 1, logs['lr']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G2GUx5CN_mCf"},"source":["**Load Model**\n","\n","Callback include CSV logging, model checkpoints (best model only), and the custom learning rate scheduler."]},{"cell_type":"code","metadata":{"id":"EANfnGlwaJcS"},"source":["best_model_file=f'drive/My Drive/Birds/enetB4_passerine_{CUTOFF}.h5'\n","with strategy.scope():\n","  base_model = tf.keras.applications.EfficientNetB4(weights='imagenet',\n","                                                      include_top=False)\n","  output = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","  output = tf.keras.layers.Dropout(0.4)(output)\n","  output = tf.keras.layers.Dense(1, activation='sigmoid',\n","                                 name='passerine')(output)\n","  model = tf.keras.models.Model(base_model.input, outputs = output)\n","  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate,\n","                                                      momentum=0.9,\n","                                                      epsilon=1),\n","                loss=tf.keras.losses.BinaryCrossentropy(),\n","                metrics=[\"accuracy\"])\n","  \n","  callbacks = [tf.keras.callbacks.CSVLogger(best_model_file.replace('.h5', '.csv')),\n","             tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file,\n","                                                verbose=1,\n","                                                save_best_only=True,\n","                                                mode=\"auto\"),\n","             StepLearningRateScheduler(),\n","             ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ani9Nc4CGKd"},"source":["**Train Model**"]},{"cell_type":"code","metadata":{"id":"AojDFtWS0m-p"},"source":["history = model.fit(train_ds,\n","          verbose=2,\n","          initial_epoch=0,\n","          steps_per_epoch=STEPS_PER_EPOCH,\n","          epochs=100,\n","          validation_data=val_ds,\n","          callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWhDQdC1tlMX"},"source":[""],"execution_count":null,"outputs":[]}]}